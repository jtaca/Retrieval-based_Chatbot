{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code based on lab 3\n",
    "# -*- coding: utf-8 -*-\n",
    "import os, re, codecs\n",
    "import nltk\n",
    "from nltk.metrics.scores import accuracy\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.metrics.distance import jaccard_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'é', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'foi', 'ao', 'ele', 'das', 'tem', 'à', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'há', 'nos', 'já', 'está', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'era', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'estão', 'você', 'tinha', 'foram', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'têm', 'numa', 'pelos', 'elas', 'havia', 'seja', 'qual', 'será', 'nós', 'tenho', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'fosse', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    }
   ],
   "source": [
    "#Define stop words\n",
    "stopWords = []\n",
    "\n",
    "with open('stopWords.txt', \"r\") as f:\n",
    "    stopWords = f.read().split()\n",
    "    \n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainFunction(listaTagsTreino, listaFrasesTreino, listaFrasesDesenvolvimento):\n",
    "    results = []\n",
    "    bestSentences = []\n",
    "    i = 0\n",
    "    while i < len(listaFrasesDesenvolvimento):\n",
    "        j = 0\n",
    "        best = 1000\n",
    "        tagId = \"VOID\"\n",
    "        bestSentence = \"\"\n",
    "        while j < len(listaFrasesTreino):\n",
    "            # It is really a distance and not a similarity measure (1-similarity)\n",
    "            result = jaccard_distance(set(listaFrasesTreino[j].split()), set(listaFrasesDesenvolvimento[i].split()))\n",
    "            #result = edit_distance(listaFrasesTreino[j].split(), listaFrasesDesenvolvimento[i].split())\n",
    "            #print(result)\n",
    "            if result < best:\n",
    "                tagId = listaTagsTreino[j]\n",
    "                bestSentence = listaFrasesTreino[j]\n",
    "                best = result\n",
    "        j = j + 1\n",
    "        results.append(tagId)\n",
    "        bestSentences.append(bestSentence)\n",
    "        i = i + 1\n",
    "    return results, bestSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    listaTagsDesenvolvimento = extrai('Corpora/dist-teste.txt',1)\n",
    "    listaFrasesDesenvolvimento = extrai('Corpora/dist-teste.txt', 2)\n",
    "\n",
    "    # Process treino\n",
    "    listaTagsTreino = extrai('Corpora/dist-treino-sem-acentos.txt', 1)\n",
    "    listaFrasesTreino = extrai('Corpora/dist-treino-sem-acentos.txt', 2)\n",
    "\n",
    "    #----- Pre-processing-----\n",
    "    listaFrasesDesenvolvimento = preProc(listaFrasesDesenvolvimento)\n",
    "    listaFrasesTreino = preProc(listaFrasesTreino)\n",
    "\n",
    "    #----- Remove stopWords-----\n",
    "    listaFrasesDesenvolvimento = removeStopWords(listaFrasesDesenvolvimento, stopWords)\n",
    "    listaFrasesTreino = removeStopWords(listaFrasesTreino, stopWords)\n",
    "\n",
    "    #----- Stemming -----\n",
    "    listaFrasesDesenvolvimento = tokStem(listaFrasesDesenvolvimento)\n",
    "    listaFrasesTreino = tokStem(listaFrasesTreino)\n",
    "\n",
    "    # Call the main function\n",
    "    listaTagsEstimada = mainFunction(listaTagsTreino , listaFrasesTreino, listaFrasesDesenvolvimento)[0]\n",
    "    fraseMaisProxima = mainFunction(listaTagsTreino , listaFrasesTreino, listaFrasesDesenvolvimento)[1]\n",
    "\n",
    "    # Show results\n",
    "    for a, b, c, d in zip(listaFrasesDesenvolvimento, listaTagsEstimada, listaTagsDesenvolvimento, fraseMaisProxima):\n",
    "        print(\"Sentence to evaluate: \", a)\n",
    "        print(\"Suggested Tag: \", b)\n",
    "        print(\"Correct Tag: \", c)\n",
    "        print(\"Closest sentence: \", d, \"\\n\\n\")\n",
    "    \n",
    "    # Find accuracy\n",
    "    print (\"Accuracy:\", accuracy(listaTagsDesenvolvimento, listaTagsEstimada))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProc(Lista):\n",
    "\tperguntas = []\n",
    "\tfor l in Lista:\n",
    "\t\t# ELIMINA ACENTOS\n",
    "\t\tl = re.sub(u\"ã\", 'a', l)\n",
    "\t\tl = re.sub(u\"á\", \"a\", l)\n",
    "\t\tl = re.sub(u\"à\", \"a\", l)\n",
    "\t\tl = re.sub(u\"õ\", \"o\", l)\n",
    "\t\tl = re.sub(u\"ô\", \"o\", l)\n",
    "\t\tl = re.sub(u\"ó\", \"o\", l)\n",
    "\t\tl = re.sub(u\"é\", \"e\", l)\n",
    "\t\tl = re.sub(u\"ê\", \"e\", l)\n",
    "\t\tl = re.sub(u\"í\", \"i\", l)\n",
    "\t\tl = re.sub(u\"ú\", \"u\", l)\n",
    "\t\tl = re.sub(u\"ç\", \"c\", l)\n",
    "\t\tl = re.sub(u\"Ã\", 'A', l)\n",
    "\t\tl = re.sub(u\"Á\", \"A\", l)\n",
    "\t\tl = re.sub(u\"À\", \"A\", l)\n",
    "\t\tl = re.sub(u\"Õ\", \"O\", l)\n",
    "\t\tl = re.sub(u\"Ô\", \"O\", l)\n",
    "\t\tl = re.sub(u\"Ô\", \"O\", l)\n",
    "\t\tl = re.sub(u\"Ó\", 'O', l)\n",
    "\t\tl = re.sub(u\"Í\", \"I\", l)\n",
    "\t\tl = re.sub(u\"Ú\", \"U\", l)\n",
    "\t\tl = re.sub(u\"Ç\", \"C\", l)\n",
    "\t\tl = re.sub(u\"É\", \"E\", l)\n",
    "\t\t# TUDO EM MINÚSCULAS\n",
    "\t\tl = l.lower()\n",
    "\t\t# ELIMINA PONTUAÇÃO\n",
    "\t\tl = re.sub(\"[?|\\.|!|:|,|;]\", '', l)\n",
    "\t\t# fica so com as perguntas\n",
    "\t\tl = re.sub(\"^\\w+\\t+[^\\w]\", '', l)\n",
    "\t\tperguntas.append(str(l))\n",
    "\treturn perguntas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# It is case insensitive\n",
    "def removeStopWords(list, stopWordList):\n",
    "\tperguntas = []\n",
    "\tfor sentence in list:\n",
    "\t\tsentence = sentence.split()\n",
    "\t\tfrase = []\n",
    "\t\tfor word in sentence:\n",
    "\t\t\tif word.lower() not in stopWordList:\n",
    "\t\t\t\tfrase.append(word)\n",
    "\t\t\tfraseAux = ' '.join(frase)\t\n",
    "\t\tperguntas.append(fraseAux)\n",
    "\treturn perguntas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokStem(perguntas):\n",
    "\tperguntas_tok_stem = []\n",
    "\tstemmer = nltk.stem.RSLPStemmer()\n",
    "\tfor l in perguntas:\n",
    "\t\tl = nltk.word_tokenize(l)\n",
    "\t\tl1 = []\n",
    "\t\tfor word in l:\n",
    "\t\t\tword = stemmer.stem(word)\n",
    "\t\t\tl1.append(word)\n",
    "\t\tl = ' '.join(l1)\n",
    "\t\tperguntas_tok_stem.append(l)\n",
    "\treturn perguntas_tok_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------\n",
    "# Print a list\n",
    "#---------------\n",
    "def print_list(list):\n",
    "\tj = 0\n",
    "\twhile j < len(list):\n",
    "\t\tprint (list[j])\n",
    "\t\tj = j + 1\n",
    "\n",
    "#---------------\n",
    "# Print both lists, side by side\n",
    "# They should have the same size\n",
    "#---------------\n",
    "def print_lists(list1, list2):\n",
    "\tj = 0\n",
    "\twhile j < len(list1):\n",
    "\t\tprint (j, list1[j] + \"\\t\" + list2[j])\n",
    "\t\tj = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrai(nameFile, numColuna):\n",
    "    file = open(nameFile, 'rU')\n",
    "    tags = []\n",
    "    sentences = []\n",
    "    for line in file:\n",
    "        field = re.search(r\"(\\w+[^\\s])\\t+(.+)\", line)\n",
    "        if field is None:\n",
    "            print (\"nada\")\n",
    "        else:\n",
    "            tag = field.group(1)\n",
    "            sentence = field.group(2)\n",
    "            tags.append(tag)\n",
    "            sentences.append(sentence)\n",
    "    file.close()\n",
    "    if numColuna == 1:\n",
    "        return tags\n",
    "    if numColuna == 2:\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nada\n",
      "nada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaotiagoaparicio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: 'U' mode is deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
