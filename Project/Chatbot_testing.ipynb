{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code based on lab 3\n",
    "# -*- coding: utf-8 -*-\n",
    "import os, re, codecs\n",
    "import nltk\n",
    "from nltk.metrics.scores import accuracy\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.metrics.distance import jaccard_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'é', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'foi', 'ao', 'ele', 'das', 'tem', 'à', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'há', 'nos', 'já', 'está', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'era', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'estão', 'você', 'tinha', 'foram', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'têm', 'numa', 'pelos', 'elas', 'havia', 'seja', 'qual', 'será', 'nós', 'tenho', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'fosse', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    }
   ],
   "source": [
    "#Define stop words\n",
    "stopWords = []\n",
    "\n",
    "with open('stopWords.txt', \"r\") as f:\n",
    "    stopWords = f.read().split()\n",
    "    \n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainFunction(listaTagsTreino, listaFrasesTreino, listaFrasesDesenvolvimento):\n",
    "    results = []\n",
    "    bestSentences = []\n",
    "    i = 0\n",
    "    while i < len(listaFrasesDesenvolvimento):\n",
    "        j = 0\n",
    "        best = 1000\n",
    "        tagId = \"VOID\"\n",
    "        bestSentence = \"\"\n",
    "        while j < len(listaFrasesTreino):\n",
    "            # It is really a distance and not a similarity measure (1-similarity)\n",
    "            result = jaccard_distance(set(listaFrasesTreino[j].split()), set(listaFrasesDesenvolvimento[i].split()))\n",
    "            #result = edit_distance(listaFrasesTreino[j].split(), listaFrasesDesenvolvimento[i].split())\n",
    "            #print(result)\n",
    "            if result < best:\n",
    "                tagId = listaTagsTreino[j]\n",
    "                bestSentence = listaFrasesTreino[j]\n",
    "                best = result\n",
    "        j = j + 1\n",
    "        results.append(tagId)\n",
    "        bestSentences.append(bestSentence)\n",
    "        i = i + 1\n",
    "    return results, bestSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    listaTagsDesenvolvimento = extrai('Corpora/dist-teste.txt',1)\n",
    "    listaFrasesDesenvolvimento = extrai('Corpora/dist-teste.txt', 2)\n",
    "\n",
    "    # Process treino\n",
    "    listaTagsTreino = extrai('Corpora/dist-treino-sem-acentos.txt', 1)\n",
    "    listaFrasesTreino = extrai('Corpora/dist-treino-sem-acentos.txt', 2)\n",
    "\n",
    "    #----- Pre-processing-----\n",
    "    listaFrasesDesenvolvimento = preProc(listaFrasesDesenvolvimento)\n",
    "    listaFrasesTreino = preProc(listaFrasesTreino)\n",
    "\n",
    "    #----- Remove stopWords-----\n",
    "    listaFrasesDesenvolvimento = removeStopWords(listaFrasesDesenvolvimento, stopWords)\n",
    "    listaFrasesTreino = removeStopWords(listaFrasesTreino, stopWords)\n",
    "\n",
    "    #----- Stemming -----\n",
    "    listaFrasesDesenvolvimento = tokStem(listaFrasesDesenvolvimento)\n",
    "    listaFrasesTreino = tokStem(listaFrasesTreino)\n",
    "\n",
    "    # Call the main function\n",
    "    listaTagsEstimada = mainFunction(listaTagsTreino , listaFrasesTreino, listaFrasesDesenvolvimento)[0]\n",
    "    fraseMaisProxima = mainFunction(listaTagsTreino , listaFrasesTreino, listaFrasesDesenvolvimento)[1]\n",
    "\n",
    "    # Show results\n",
    "    for a, b, c, d in zip(listaFrasesDesenvolvimento, listaTagsEstimada, listaTagsDesenvolvimento, fraseMaisProxima):\n",
    "        print(\"Sentence to evaluate: \", a)\n",
    "        print(\"Suggested Tag: \", b)\n",
    "        print(\"Correct Tag: \", c)\n",
    "        print(\"Closest sentence: \", d, \"\\n\\n\")\n",
    "    \n",
    "    # Find accuracy\n",
    "    print (\"Accuracy:\", accuracy(listaTagsDesenvolvimento, listaTagsEstimada))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProc(Lista):\n",
    "    perguntas = []\n",
    "    for l in Lista:\n",
    "        # ELIMINA ACENTOS\n",
    "        l = re.sub(u\"ã\", 'a', l)\n",
    "        l = re.sub(u\"á\", \"a\", l)\n",
    "        l = re.sub(u\"à\", \"a\", l)\n",
    "        l = re.sub(u\"õ\", \"o\", l)\n",
    "        l = re.sub(u\"ô\", \"o\", l)\n",
    "        l = re.sub(u\"ó\", \"o\", l)\n",
    "        l = re.sub(u\"é\", \"e\", l)\n",
    "        l = re.sub(u\"ê\", \"e\", l)\n",
    "        l = re.sub(u\"í\", \"i\", l)\n",
    "        l = re.sub(u\"ú\", \"u\", l)\n",
    "        l = re.sub(u\"ç\", \"c\", l)\n",
    "        l = re.sub(u\"Ã\", 'A', l)\n",
    "        l = re.sub(u\"Á\", \"A\", l)\n",
    "        l = re.sub(u\"À\", \"A\", l)\n",
    "        l = re.sub(u\"Õ\", \"O\", l)\n",
    "        l = re.sub(u\"Ô\", \"O\", l)\n",
    "        l = re.sub(u\"Ô\", \"O\", l)\n",
    "        l = re.sub(u\"Ó\", 'O', l)\n",
    "        l = re.sub(u\"Í\", \"I\", l)\n",
    "        l = re.sub(u\"Ú\", \"U\", l)\n",
    "        l = re.sub(u\"Ç\", \"C\", l)\n",
    "        l = re.sub(u\"É\", \"E\", l)\n",
    "        # TUDO EM MINÚSCULAS\n",
    "        l = l.lower()\n",
    "        # ELIMINA PONTUAÇÃO\n",
    "        l = re.sub(\"[?|\\.|!|:|,|;]\", '', l)\n",
    "        # fica so com as perguntas\n",
    "        l = re.sub(\"^\\w+\\t+[^\\w]\", '', l)\n",
    "        perguntas.append(str(l))\n",
    "    return perguntas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# It is case insensitive\n",
    "def removeStopWords(list, stopWordList):\n",
    "    perguntas = []\n",
    "    for sentence in list:\n",
    "        sentence = sentence.split()\n",
    "        frase = []\n",
    "        for word in sentence:\n",
    "            if word.lower() not in stopWordList:\n",
    "                frase.append(word)\n",
    "            fraseAux = ' '.join(frase)\t\n",
    "        perguntas.append(fraseAux)\n",
    "    return perguntas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokStem(perguntas):\n",
    "    perguntas_tok_stem = []\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    for l in perguntas:\n",
    "        l = nltk.word_tokenize(l)\n",
    "        l1 = []\n",
    "        for word in l:\n",
    "            word = stemmer.stem(word)\n",
    "            l1.append(word)\n",
    "        l = ' '.join(l1)\n",
    "        perguntas_tok_stem.append(l)\n",
    "    return perguntas_tok_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------\n",
    "# Print a list\n",
    "#---------------\n",
    "def print_list(list):\n",
    "    j = 0\n",
    "    while j < len(list):\n",
    "        print (list[j])\n",
    "        j = j + 1\n",
    "\n",
    "#---------------\n",
    "# Print both lists, side by side\n",
    "# They should have the same size\n",
    "#---------------\n",
    "def print_lists(list1, list2):\n",
    "    j = 0\n",
    "    while j < len(list1):\n",
    "        print (j, list1[j] + \"\\t\" + list2[j])\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrai(nameFile, numColuna):\n",
    "    file = open(nameFile, 'rU')\n",
    "    tags = []\n",
    "    sentences = []\n",
    "    for line in file:\n",
    "        field = re.search(r\"(\\w+[^\\s])\\t+(.+)\", line)\n",
    "        if field is None:\n",
    "            print (\"nada\")\n",
    "        else:\n",
    "            tag = field.group(1)\n",
    "            sentence = field.group(2)\n",
    "            tags.append(tag)\n",
    "            sentences.append(sentence)\n",
    "    file.close()\n",
    "    if numColuna == 1:\n",
    "        return tags\n",
    "    if numColuna == 2:\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nada\n",
      "nada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaotiagoaparicio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: 'U' mode is deprecated\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-a56cc5742a84>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Call the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlistaTagsEstimada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmainFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistaTagsTreino\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlistaFrasesTreino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistaFrasesDesenvolvimento\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mfraseMaisProxima\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmainFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistaTagsTreino\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlistaFrasesTreino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistaFrasesDesenvolvimento\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-e87cc33194bd>\u001b[0m in \u001b[0;36mmainFunction\u001b[0;34m(listaTagsTreino, listaFrasesTreino, listaFrasesDesenvolvimento)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistaFrasesTreino\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# It is really a distance and not a similarity measure (1-similarity)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaccard_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistaFrasesTreino\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistaFrasesDesenvolvimento\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;31m#result = edit_distance(listaFrasesTreino[j].split(), listaFrasesDesenvolvimento[i].split())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m#print(result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/nltk/metrics/distance.py\u001b[0m in \u001b[0;36mjaccard_distance\u001b[0;34m(label1, label2)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \"\"\"\n\u001b[0;32m--> 196\u001b[0;31m     return (len(label1.union(label2)) - len(label1.intersection(label2))) / len(\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
